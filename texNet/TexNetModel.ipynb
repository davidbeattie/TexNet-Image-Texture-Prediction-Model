{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultraleap Image Texture Prediction Model Â© Ultraleap Limited 2020\n",
    "\n",
    "Licensed under the Ultraleap closed source licence agreement; you may not use this file except in compliance with the License.\n",
    "\n",
    "A copy of this License is included with this download as a separate document. \n",
    "\n",
    "Alternatively, you may obtain a copy of the license from: https://www.ultraleap.com/closed-source-licence/\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TexNet architecture and experiment code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the core code used for results presented in the paper, \"Incorporating the Perception of Visual Roughness into the Design of Mid-Air Haptic Textures\", which can be found at: https://dl.acm.org/doi/10.1145/3385955.3407927\n",
    "\n",
    "In order to run this model there are some prerequisite Python libraries that you should have installed. The code was tested with version shown in brackets. If you do not have any of these libraries then use the commands below in your [Jupyter notebook](https://jupyter.org/install.html \"\"): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install \"tensorflow-gpu==2.1.0\"\n",
    "!{sys.executable} -m pip install \"keras==2.3.1\"\n",
    "!{sys.executable} -m pip install \"pandas==0.25.1\"\n",
    "!{sys.executable} -m pip install \"scikit-learn==0.21.3\"\n",
    "!{sys.executable} -m pip install \"scikit-image==0.15.0\"\n",
    "!{sys.executable} -m pip install \"opencv-python==4.2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the TexNet model\n",
    "First of all let's import the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, concatenate\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Nadam, sgd\n",
    "from skimage import transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cv2 import imread\n",
    "from skimage.feature.texture import greycomatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data set\n",
    "We now load the prepared .csv file that contains the list of images from the [Penn Haptic Texture ToolKit (HaTT)](https://repository.upenn.edu/meam_papers/299/, \"\"). *This image data base must be downloaded separately from the link provided and referenced at the location where you save it.* In order to use the correct .csv file, we provide an additional Jupyter notebook that produces the correctly formatted file. \n",
    "\n",
    "**Please run [DataProcessing.ipynb](../notebooks/DataProcessing.ipynb) first if you have not yet done so before continuing.**\n",
    "\n",
    "Running the above notebook first will output a file with the file name:\n",
    "\n",
    "*date_time_**texturedim**_**outlierstate**.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this line and include link to file output via DataProcessing.ipynb, stored in 'input_data/' folder.\n",
    "#file = *DataProcessing.ipynb output .csv file*\n",
    "\n",
    "# Check if file or data frame passed to function.\n",
    "if isinstance(file, pd.DataFrame):\n",
    "    data_frame = file\n",
    "if not os.path.exists(file):\n",
    "    print(\"The file %s does not exist!\" % file)\n",
    "else:\n",
    "    data_frame = pd.read_csv(r\"{}\".format(file), error_bad_lines=False)  # Create data frame from file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "Now that we have initialised out data set and imported it as a Pandas data frame, we need to set some global parameters for our training.\n",
    "\n",
    "* **IMAGE_DIR** - the path to your downloaded HaTT image data set.\n",
    "* **IMAGE_SIZE** - Associated image size for computation. From 32 - 1024. Output images are square.\n",
    "* **TEST_TEXTURE_LIST** - If a specific list of test image textures is required then these can be input here. The output file from *'DataProcessing.ipynb'* must be queried to find image names.\n",
    "* **PREDICTOR_VARIABLE** - Texture dimension to predict. Select from 'roughness', 'bumpiness', 'hardness', 'stickiness', 'warmness'. Can be median or mean: 'mean_{dimension}'.\n",
    "* **EPOCHS** - How many epochs you require the model to train over. Default is 150.\n",
    "* **BATCH_SIZE** - Set custom batch_size. Default is 1.\n",
    "\n",
    "Using the above parameters we will be able to compile and train a model that matches those produced in our paper. You could also train the model to learn and predict different texture dimensions, such as bumpiness, or hardness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"input_data/penn_images_hatt/*.bmp\"\n",
    "IMAGE_SIZE = 256\n",
    "TEST_TEXTURE_LIST = ['denim_square', 'cork_square', 'plastic_mesh_2_square', 'brick_2_square', 'bubble_envelope_square', 'silk_1_square', 'paper_plate_2_square', 'metal_mesh_square', 'glitter_paper_square']\n",
    "PREDICTOR_VARIABLE = \"median_roughness\"\n",
    "\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating our different feature sets\n",
    "This model utilises a number of different data inputs, from individual images, to computed Grey-Level Co-Occurrence Matrices (GLCMs), as well as Haralick features computed from each GLCM. The following functions produce various different sets of these data, ready to be utilised during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeatures(object):\n",
    "    \"\"\"Feature computation class to generate optimal GLCMs and equivalent Haralick features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **args):\n",
    "        \"\"\"Initialise the ImageFeatures class and pass distance, angle values for computation of matrices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        distance: array_like, optional\n",
    "            Integer type list of pixel pair distance offsets.\n",
    "        angles: array_like, optional  - [0, 45, 90, 135]\n",
    "            Integer type list of angles in degrees.\n",
    "        \"\"\"\n",
    "        self.distance = args.get('distance')\n",
    "        self.angle = args.get('angle')\n",
    "\n",
    "    def convert_image(self, image, image_size=256, greyscale=True, resize=True):\n",
    "        \"\"\"Rescale images from initial input size to reduced size. Image should be square. Will be resized as square if\n",
    "        optional argument 'image_size' is given.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image: path/to/file\n",
    "            Image file path. .jpg, .png, or .bmp formatted.\n",
    "        image_size: int, optional\n",
    "            Size that image should be resized to. Default = 256.\n",
    "        greyscale: bool, optional\n",
    "            Sets whether image should be converted to greyscale or colour. Default = True\n",
    "        resize: bool, optional\n",
    "            If True, then image will be resized to the 'image_size' (w x h). Default = True.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        converted_image: array_like, uint8\n",
    "            Returns an image as a 2D array of grey level values (0 - 255) as type uint8. If greyscale is set to False,\n",
    "            then returned image will be 3x2D arrays corresponding to RGB channels.\n",
    "        \"\"\"\n",
    "        if greyscale:\n",
    "            converted_image = imread(image, 0)\n",
    "        else:\n",
    "            converted_image = imread(image, 1)\n",
    "\n",
    "        if resize and image_size is not None:\n",
    "            converted_image = transform.resize(converted_image, output_shape=(image_size, image_size))\n",
    "        else:\n",
    "            print(\"Error: Image size not given. Please include a reshaped image size.\")\n",
    "        return (converted_image * 255).astype('uint8')\n",
    "\n",
    "    def create_matrix(self, image, distance=None, angle=None, symmetric=False, normalise=False):\n",
    "        \"\"\"Produces a grey level co-occurence matrix based on input image, distance by which to compare pixel grey-level\n",
    "        co-occurences, and corresponding angle.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image: array_like\n",
    "            Having converted images into uint (preferably 256x256), pass as input to create matrix.\n",
    "        distance: int, optional\n",
    "            A specific distance value by which co-occurring grey-levels should be tallied across. Default = 1\n",
    "        angle: int, optional\n",
    "            A specific angle in degrees by which the matrix should be scanned across. Default = 0\n",
    "        symmetric: bool, optional\n",
    "            Determines whether output matrix is symmetric. Handled by sk-image. Default = False.\n",
    "        normalise: bool, optional\n",
    "            If true, matrix values are the probablities of co-occurring pixel grey-level values, where sum = 1.\n",
    "            Handled by sk-image. Default = False.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        matrix: 4D ndarray\n",
    "            Output is a grey-level matrix, matrix[image_size, image_size, distance, angle] is returned. Matrix\n",
    "            identifies where a given grey level value (0 - 255) occurs in comparison to an equivalent value for a given\n",
    "            distance and angle. Output is uint32 if 'normalise' = True. Otherwise, float64. Handled by sk-image to\n",
    "            reduce processing time.\n",
    "        \"\"\"\n",
    "        if distance is None:\n",
    "            distance = np.array([1])\n",
    "        if angle is None:\n",
    "            angle = np.array([0])\n",
    "        return greycomatrix(image, distance, angle, symmetric=symmetric, normed=normalise)\n",
    "\n",
    "    def create_haralick(self, matrix):\n",
    "        \"\"\"Function to compute 7 Haralick features used as factors to determine the level of underlying texture\n",
    "        dimension contained within an image whose matrix has been calculated. We compute specific features related\n",
    "        to different independent statistical properties that can be obtained from GLCMs.\n",
    "\n",
    "        Matrices must be normalised in order to correctly calculate each Haralick feature.\n",
    "\n",
    "        Contrast Group: This group identifies pixel co-occurrences in relation to their distance from the GLCM diagonal.\n",
    "            contrast: float64, [0 - 10e6]\n",
    "                'sum of squares variance'. Weights increase exponentially as values move away from diagonal. Therefore,\n",
    "                an image that has a high contrast value signifies co-occurring pixel values occur far from the diagonal.\n",
    "            homogeneity: float64, [0 - 1]\n",
    "                Weights decrease exponentially away from the diagonal, meaning a matrix's homogeneity value is higher\n",
    "                when its contrast is very low (close to diagonal). Therefore, images with very little variance will\n",
    "                produce a homogeneity value that approaches 1.\n",
    "\n",
    "        Orderliness Group: This group explains how 'regular' the pixel value differences are within a matrix.\n",
    "            asm: float64, [0 - >1]\n",
    "                'Angular Second Moment', if a matrix contains large numbers for only a few pixel co-occurrences, then\n",
    "                asm will be high, indicating that the underlying texture is some repeated pattern (orderly). Conversely,\n",
    "                if asm is low, then the underlying texture will be very randomised in changes in grey level.\n",
    "            energy: float64, [0 - 1]\n",
    "                This is the square root of asm.\n",
    "\n",
    "        Descriptives Group: This group calculates descriptive statistics such as mean, stdev on the matrix entries, not\n",
    "                            the image values themselves.\n",
    "                mean: float64\n",
    "                    matrix mean demonstrates the frequency of occurrence of one pixel value (j) being found across a\n",
    "                    distance, and angle input value, at its (i) neighbour. For symmetric matrices, calculating mean\n",
    "                    for i will be identical to j mean.\n",
    "                stdev: float64\n",
    "                    square root of the variance in terms of the dispersion of values around the calculated mean for\n",
    "                    pixel co-occurrences.\n",
    "                corr: float64\n",
    "                    Correlation that identifies the linear dependency of grey levels on those of neighbouring pixels.\n",
    "                    0 (uncorrelated) and 1 (perfectly correlated). This measure is independent of all other Haralick\n",
    "                    features. High values denote high predictability of pixel relationships.\n",
    "                cls_shade: float64\n",
    "                    Cluster Shade measures the skewness and uniformity in the computed matrix. Higher values suggest\n",
    "                    more asymmetry around the mean.\n",
    "                cls_prom: float64\n",
    "                    Cluster Prominence measures asymmetry in the matrix. Similar characteristics to Cluster Shade\n",
    "                    (cls_shade).\n",
    "\n",
    "        Refer to:\n",
    "            R. M. Haralick, K. Shanmugam and I. Dinstein, \"Textural Features for Image Classification,\"\n",
    "            in IEEE Transactions on Systems, Man, and Cybernetics, vol. SMC-3, no. 6, pp. 610-621, Nov. 1973,\n",
    "            doi: 10.1109/TSMC.1973.4309314.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        matrix: ndarray - 2D\n",
    "            An input matrix array containing co-occurring grey-level values for an image. Must first be normalised.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        features: ndarray\n",
    "            Outputs a list of 9 Haralick features calculated from the input matrix.\n",
    "        \"\"\"\n",
    "        # Initialise a mesh grid\n",
    "        level = matrix.shape[0]\n",
    "        I, J = np.ogrid[0:level, 0:level]\n",
    "        ij = I * J\n",
    "\n",
    "        # Compute Homogeneity weights and apply to matrix for homogeneity calculation.\n",
    "        homo_weight = 1. / (1. + (I - J) ** 2)\n",
    "        homo = np.apply_over_axes(np.sum, (matrix * homo_weight), axes=(0, 1))[0, 0]\n",
    "\n",
    "        # Compute Contrast weights. Apply to matrix.\n",
    "        con_weight = (I - J) ** 2\n",
    "        contrast = np.apply_over_axes(np.sum, (matrix * con_weight), axes=(0, 1))[0, 0]\n",
    "\n",
    "        # Compute ASM (angular second moment). Take square root for energy calculation.\n",
    "        asm = np.apply_over_axes(np.sum, (matrix ** 2), axes=(0, 1))[0, 0]\n",
    "        energy = np.sqrt(asm)\n",
    "\n",
    "        k = np.arange(len(matrix))\n",
    "        tk = np.arange(2 * (len(matrix)))\n",
    "        p = matrix / matrix.sum()\n",
    "        pravel = p.ravel()\n",
    "        px = p.sum(0)\n",
    "        py = p.sum(1)\n",
    "\n",
    "        ux = np.dot(px, k)\n",
    "        uy = np.dot(py, k)\n",
    "        vx = np.dot(px, k ** 2) - ux ** 2\n",
    "        vy = np.dot(py, k ** 2) - uy ** 2\n",
    "        sx = np.sqrt(vx)\n",
    "        sy = np.sqrt(vy)\n",
    "\n",
    "        if sx == 0.0 or sy == 0.0:\n",
    "            corr = 1.0\n",
    "        else:\n",
    "            # Compute Correlation value across matrix\n",
    "            corr = (1. / sx / sy) * (np.dot(ij.ravel(), pravel) - ux * uy)\n",
    "\n",
    "        px_plus_y = np.zeros(2 * len(matrix), np.double)\n",
    "        px_minus_y = np.zeros(len(matrix), np.double)\n",
    "\n",
    "        idx1 = np.arange(0, level * 2)\n",
    "        idx2 = np.arange(0, level)\n",
    "\n",
    "        tmp1 = np.array([np.array(I + J).reshape(-1, 1), np.array(matrix).reshape(-1, 1)])\n",
    "        tmp2 = np.array([np.abs(I - J).reshape(-1, 1), np.array(matrix).reshape(-1, 1)])\n",
    "\n",
    "        for i in idx1:\n",
    "            px_plus_y[i] = tmp1[1][tmp1[0] == i].sum()\n",
    "\n",
    "        for i in idx2:\n",
    "            px_minus_y[i] = tmp2[1][tmp2[0] == i].sum()\n",
    "\n",
    "        # Compute mean and standard deviation of matrix.\n",
    "        mean = np.dot(tk, px_plus_y)\n",
    "        stdev = np.sqrt(np.dot(tk ** 2, px_plus_y) - mean ** 2)\n",
    "\n",
    "        # Calculate Cluster Shade and Prominence weights, then obtain values by applying across matrix.\n",
    "        shade_weight = np.power((I + J - ux - uy), 3)\n",
    "        prom_weight = np.power((I + J - ux - uy), 4)\n",
    "\n",
    "        cls_shade = np.apply_over_axes(np.sum, (matrix * shade_weight), axes=(0, 1))[0, 0]\n",
    "        cls_prom = np.apply_over_axes(np.sum, (matrix * prom_weight), axes=(0, 1))[0, 0]\n",
    "\n",
    "        return np.array([homo, asm, contrast, energy, corr, mean, stdev, cls_shade, cls_prom])\n",
    "\n",
    "    def compute_chi_sum(self, matrix):\n",
    "        \"\"\"This function computes a Chi-Square value for an input matrix. This value can be used to ascertain which\n",
    "        particular distance value and angle used to calculate the matrix has enabled the underlying structure to be\n",
    "        captured. High Chi-Square values will indicate that the input matrix has more succesfully captured the texture\n",
    "        structure within an image.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        matrix: ndarray - 2D\n",
    "            An input matrix array containing co-occurring grey-level values for an image. Should be non-normalised.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        chi_sum: float64\n",
    "            Provides a float64 value of the computed Chi-Square value that indicates the goodness of fit of the matrix\n",
    "            computed over a specific distance and angle, in relation to the underlying texture structure in the\n",
    "            corresponding image.\n",
    "\n",
    "        Refer to:\n",
    "            Zucker, Steven W., and Demetri Terzopoulos. \"Finding structure in co-occurrence matrices\n",
    "            for texture analysis.\" Computer graphics and image processing 12, no. 3 (1980): 286-308.\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate matrix row and column totals.\n",
    "        row_matrix = np.repeat(matrix.sum(axis=0), matrix.shape[0], axis=0).reshape(matrix.shape[0], matrix.shape[1])\n",
    "        col_matrix = np.repeat(matrix.sum(axis=1), matrix.shape[0], axis=0).reshape(matrix.shape[0], matrix.shape[1]).T\n",
    "\n",
    "        # Calculate multiplied row and column totals then divide by the sum of the non-normalised matrix.\n",
    "        matrix_rc_totals = (row_matrix * col_matrix) / matrix.sum()\n",
    "\n",
    "        # Obtain the expected values for each cell in the matrix\n",
    "        expected_values = (matrix - matrix_rc_totals) ** 2\n",
    "\n",
    "        # Return the sum of all values where rows and columns sums are non zero.\n",
    "        return np.sum(np.divide(expected_values, matrix_rc_totals, where=(matrix_rc_totals != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing features and generating corresponding lists of variables.\n",
    "We have generated individual functions that can produce our GLCMs and Haralick features. We can now pass in our image data set and create the corresponding features as we like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesLists:\n",
    "    \"\"\"This class is essentially a composite class of some functions in the ImageFeatures class. The functions in\n",
    "    this class enable numerous images to be processed simultaneously, and subsequently, to generate optimal matrices for\n",
    "    each image, along with additional Haralick features, and tuples of the optimal distance and angle values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_dir, **args):\n",
    "        \"\"\"Initialise the class and provide a directory of images that should be processed.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_dir: str, path\n",
    "            A path that contains the associated images that should be processed.\n",
    "        image_size: int, optional\n",
    "            A specified image resize value.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.image_size = args.get('image_size')\n",
    "        self.image_features = ImageFeatures()\n",
    "\n",
    "    def create_image_list(self):\n",
    "        \"\"\"Function to read each image from the input directory passed to the class initialisation function.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image_list: ndarray\n",
    "            A list of processed images in uint8 format. Calls convert_image in ImageFeatures.\n",
    "        \"\"\"\n",
    "        image_list = []\n",
    "        for image in glob.glob(self.image_dir):\n",
    "            image_list.append(self.image_features.convert_image(image))\n",
    "        return image_list\n",
    "\n",
    "    def create_matrix_list(self, image_list, distances, angles):\n",
    "        \"\"\"This function will process the image list output from 'create_image_list' and subsequently calculate optimal\n",
    "        matrices for each image, based on the list of distances and angles provided.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_list: uint8, array_like\n",
    "            A list of processed images in uint8 format.\n",
    "        distances: int, array_like\n",
    "            A list of integer value distances that matrices should be calculated for.\n",
    "        angles: int, array_like\n",
    "            A list of integer value angles in degrees, that each matrix should be computed across.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        matrix_list: float64, 2D array\n",
    "            A list of optimal matrix arrays that have captured the underlying texture in each image\n",
    "            based on Chi-Square calculations.\n",
    "        inputs_list: tuple of ints, array_like\n",
    "            A list of tuples that contain the distance and angle combination that produced the highest Chi-Square value,\n",
    "            highlighting the underlying structure in a texture image.\n",
    "        haralick_list: 1d numpy array\n",
    "            A list of corresponding Haralick features computed from an optimal matrix. The order of features is:\n",
    "                Homogeneity\n",
    "                Contrast\n",
    "                Energy\n",
    "                Correlation\n",
    "                Mean\n",
    "                Standard Deviation\n",
    "                Cluster Shade\n",
    "                Cluster Prominence\n",
    "        \"\"\"\n",
    "        matrix_list = []\n",
    "        inputs_list = []\n",
    "        haralick_list = []\n",
    "        chisum = np.zeros(shape=(len(distances), len(angles)))\n",
    "\n",
    "        # Compute all possible permutations of distances and angles to calculate matrices.\n",
    "        perms = list(itertools.product(np.arange(0, len(distances)), np.arange(0, len(angles))))\n",
    "\n",
    "        for image in image_list:\n",
    "            non_norm_mat = self.image_features.create_matrix(image, distances, angles)\n",
    "            for i, perm in enumerate(perms):\n",
    "                # Calculate each ChiSquare value for matrix with distance/angle combinations. Store best combination.\n",
    "                chisum[perm[0], perm[1]] = self.image_features.compute_chi_sum(non_norm_mat[:, :, perm[0], perm[1]])\n",
    "                max_chi = np.unravel_index(np.argmax(chisum, axis=None), chisum.shape)\n",
    "                inputs_list.append(tuple((distances[max_chi[0]], angles[max_chi[1]])))\n",
    "\n",
    "            # Calculate normalised matrix with optimal distance/angle values.\n",
    "            optimal_matrix = self.image_features.create_matrix(image, distance=[distances[max_chi[0]]],\n",
    "                                                               angle=[angles[max_chi[1]]], symmetric=False,\n",
    "                                                               normalise=True)\n",
    "            matrix_list.append(optimal_matrix)\n",
    "\n",
    "            # Calculate haralick features from optimal matrix.\n",
    "            haralick = self.image_features.create_haralick(optimal_matrix[:, :, 0, 0])\n",
    "            haralick_list.append(haralick)\n",
    "\n",
    "        # return each of the lists of optimal matrices, distance/angle combos, and haralick feature values.\n",
    "        return matrix_list, inputs_list, haralick_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting our data into training, validation, and test sets.\n",
    "In addition to generating this new data, we must also separate our data set into train, test and validation sets. The following functions prepare our data as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareData(object):\n",
    "    \"\"\"This object class can be instantiated in order to conduct various splitting and rescaling requirements before our\n",
    "    model is to be trained.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, test_texture_list=None, train_size=0.9, shuffle=True):\n",
    "        \"\"\"Initialise the class for the purpose of preparing our data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_texture_list: array_like(str), optional\n",
    "            If the user would like to split the data set to exclude a specific set of images as a test set for model\n",
    "            prediction, a list of corresponding string values can be provided. This must be the specific name for each\n",
    "            texture. The initial data frame created from the DataProcessing.ipynb should be queried for these names.\n",
    "        train_size: float, optional\n",
    "            If a specific training data size is to be used then a value by which the input data should be split can be\n",
    "            set.\n",
    "        shuffle: bool, optional\n",
    "            Sets whether data should be shuffled during the splitting into train, test and validation sets.\n",
    "        \"\"\"\n",
    "        self.test_list = test_texture_list\n",
    "        self.train_size = train_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def append_feature_data(self, **args):\n",
    "        \"\"\"This function will concatenate the initial data frame from DataProcessing.ipynb with any of the additional\n",
    "        feature data created in the previous steps, such as image arrays, matrices, haralick features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_frame: Pandas Dataframe, optional\n",
    "            This should be the data frame obtained from running DataProcessing.ipynb.\n",
    "        image_list: array_like, optional\n",
    "            A list of corresponding images that should be processed by the model.\n",
    "        matrix_list: array_like, optional\n",
    "            This list should contain each matrix that has been computed for any image.\n",
    "        haralick_list: array_like, optional\n",
    "            A list of float64 values that contains the computed Haralick features for any of the images in the data set.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        appended_df: Pandas Dataframe\n",
    "            A concatenated data frame that contains the appended feature lists passed as input.\n",
    "        \"\"\"\n",
    "        data_frame = args.get('data_frame')\n",
    "        image_list = args.get('image_list')\n",
    "        matrix_list = args.get('matrix_list')\n",
    "        haralick_list = args.get('haralick_list')\n",
    "\n",
    "        if data_frame is not None:\n",
    "            features_df = pd.DataFrame()\n",
    "        if image_list is not None:\n",
    "            features_df['image_list'] = [image / 255 for image in image_list]\n",
    "        if matrix_list is not None:\n",
    "            features_df['matrix_list'] = matrix_list\n",
    "        if haralick_list is not None:\n",
    "            # Create Pandas DataFrame with columns specific for each Haralick feature.\n",
    "            features_df['har_homo'] = [item[0] for item in haralick_list]\n",
    "            features_df['har_contrast'] = [item[2] for item in haralick_list]\n",
    "            features_df['har_energy'] = [item[3] for item in haralick_list]\n",
    "            features_df['har_corr'] = [item[4] for item in haralick_list]\n",
    "            features_df['har_mean'] = [item[5] for item in haralick_list]\n",
    "            features_df['har_stdev'] = [item[6] for item in haralick_list]\n",
    "            features_df['har_cls_shade'] = [item[7] for item in haralick_list]\n",
    "            features_df['har_cls_prom'] = [item[8] for item in haralick_list]\n",
    "\n",
    "        appended_df = pd.concat([data_frame, features_df], axis=1)\n",
    "        appended_df.set_index('tex_name', drop=True, inplace=True)\n",
    "        return appended_df\n",
    "\n",
    "    def scale_data(self, data, rescale_min, rescale_max):\n",
    "        \"\"\"Helper function that will rescale any input data to a specified range.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array_like, Pandas Series\n",
    "            A column from a Pandas DataFrame whose values should be rescaled.\n",
    "        rescale_min, rescale_max: int\n",
    "            Integer values by which the range of values in the 'data' input should be rescaled to.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        rescaled_data: array_like, Pandas Series\n",
    "            The rescaled column of data ranging from some given min - max value range.\n",
    "        \"\"\"\n",
    "        col_max = data.max()\n",
    "        col_min = data.min()\n",
    "        return data.apply(lambda x: ((x - col_min) / (col_max - col_min)) * (rescale_max - rescale_min) + rescale_min)\n",
    "\n",
    "    def scale_df(self, df, rescale_min, rescale_max):\n",
    "        \"\"\"Helper function to rescale all columns in a Pandas dataframe if this is required.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df: array_like, Pandas DataFrame\n",
    "            A complete Pandas DataFrame whose values should be rescaled.\n",
    "        rescale_min, rescale_max: int\n",
    "            Integer values by which the range of values in the 'df' input should be rescaled to.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        new_df: Pandas DataFrame\n",
    "            A new data frame containing rescaled column data ranging from some given min - max value range.\n",
    "        \"\"\"\n",
    "        new_df = pd.DataFrame(df, copy=True)\n",
    "        for i in range(len(new_df.columns)):\n",
    "            if new_df.iloc[:, i].dtypes == 'float64':\n",
    "                new_df.iloc[:, i] = new_df.iloc[:, i].apply(\n",
    "                    lambda x: ((x - new_df.iloc[:, i].min()) / (new_df.iloc[:, i].max() - new_df.iloc[:, i].min())) *\n",
    "                              (rescale_max - rescale_min) + rescale_min)\n",
    "        return new_df\n",
    "\n",
    "    def reshape_array(self, data, shape):\n",
    "        \"\"\"Helper function that will reshape a given set of input data to some alternative shape.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array_like\n",
    "            Some list or Pandas Series of data that should reshaped.\n",
    "        shape: tuple(int)\n",
    "            A particular shape by which the input data should be converted into.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        reshaped_data: array_like\n",
    "            The converted data based on the shape value given.\n",
    "        \"\"\"\n",
    "        data = np.array(data.tolist())\n",
    "        return np.reshape(data, newshape=shape)\n",
    "\n",
    "    def split_for_training(self, data):\n",
    "        \"\"\"This function will split data input into separate train, validation and test sets.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array_like\n",
    "            Pandas DataFrame of input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        train, test, val: split Pandas data frames.\n",
    "        \"\"\"\n",
    "        test, val = None, None\n",
    "\n",
    "        if self.test_list is not None:\n",
    "            train = data.drop(index=self.test_list)\n",
    "            test = data.drop(train.index)\n",
    "            train, val = train_test_split(train, test_size=len(self.test_list), shuffle=self.shuffle)\n",
    "        else:\n",
    "            train, test = train_test_split(data, test_size=1 - self.train_size, shuffle=self.shuffle)\n",
    "            train, val = train_test_split(train, test_size=len(test), shuffle=self.shuffle)\n",
    "\n",
    "        return train, test, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the model for training\n",
    "We now need to create and prepare the model so that it can accept the different input features we may wish to use for training. This model is broken down into distinct architectures depending on the input data. For image and matrix training a CNN is used (TexNetConv2D), whereas an MLP (TexNetMLP) is used for Haralick feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TexNetModels(object):\n",
    "    \"\"\"The TexNet model class can be instantiated in order to initialise the different networks (CNN & MLP) for training\n",
    "    on our different data types. In addition we can run the training step from this object too.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialise the TexNet model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        kwargs: dictionary of params.\n",
    "            If the user wishes to prepare and train a model with the various different input features then this\n",
    "            dict object can be used to state which parameters they would like to use.\n",
    "        \"\"\"\n",
    "        self.train_i = kwargs.get('image_training')\n",
    "        self.train_m = kwargs.get('matrix_training')\n",
    "        self.train_h = kwargs.get('haralick_training')\n",
    "\n",
    "        self.train_i_data = kwargs.get('train_image_data')\n",
    "        self.train_m_data = kwargs.get('train_matrix_data')\n",
    "        self.train_h_data = kwargs.get('train_haralick_data')\n",
    "\n",
    "        self.test_i_data = kwargs.get('test_image_data')\n",
    "        self.test_m_data = kwargs.get('test_matrix_data')\n",
    "        self.test_h_data = kwargs.get('test_haralick_data')\n",
    "\n",
    "        self.val_i_data = kwargs.get('val_image_data')\n",
    "        self.val_m_data = kwargs.get('val_matrix_data')\n",
    "        self.val_h_data = kwargs.get('val_haralick_data')\n",
    "\n",
    "        self.train_t = kwargs.get('train_target')\n",
    "        self.test_t = kwargs.get('test_target')\n",
    "        self.val_t = kwargs.get('val_target')\n",
    "\n",
    "    def texnet_conv2d(self, input_data):\n",
    "        \"\"\" Architecture of the CNN model that can be trained on 2D input data (images and matrices).\n",
    "        Architecture is 3 Keras Conv2D layers with window size of 7x7 and 3x3, 16 filters, 'relu' activations,\n",
    "        and He normal kernel initialisation. Max pooling layers between each Conv2D layer, window size 4x4 and 2x2.\n",
    "        Finally, a Dense layer with L2 kernel regularisation set at 0.005.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_data: array_like\n",
    "            Expects some 2D matrix input of shape 256x256.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        texnet_conv2D: Keras Convolutional model.\n",
    "        \"\"\"\n",
    "        _input = Input(shape=input_data[0].shape)  # Set input shape from length of first dimension in matrix input.\n",
    "\n",
    "        # Initialise layers\n",
    "        texnet_conv2D = Conv2D(16, (7, 7), activation='relu', padding='same', kernel_initializer='he_normal')(_input)\n",
    "        texnet_conv2D = MaxPooling2D(pool_size=(4, 4))(texnet_conv2D)\n",
    "        texnet_conv2D = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "            texnet_conv2D)\n",
    "        texnet_conv2D = MaxPooling2D(pool_size=(2, 2))(texnet_conv2D)\n",
    "        texnet_conv2D = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "            texnet_conv2D)\n",
    "        texnet_conv2D = MaxPooling2D(pool_size=(2, 2))(texnet_conv2D)\n",
    "\n",
    "        # Flatten and initialise Dense layer with 16 filters and L2 kernal regularisation.\n",
    "        texnet_conv2D = Flatten()(texnet_conv2D)\n",
    "        texnet_conv2D = Dense(16, activation='relu', kernel_regularizer=l2(0.005))(texnet_conv2D)\n",
    "        texnet_conv2D = Model(inputs=_input, outputs=texnet_conv2D)\n",
    "        return texnet_conv2D\n",
    "\n",
    "    def texnet_mlp(self, input_data):\n",
    "        \"\"\" Architecture of the Multi-Layer Perceptron that can be trained on Haralick feature data.\n",
    "        Architecture is 2 Keras Dense layers with 16 filters, 'relu' activations,\n",
    "        and He normal kernel initialisation. The second Dense layer features L2 kernel regularisation set at 0.01.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_data: array_like\n",
    "            Expects some 1D NumPy array.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tex_net_conv2D: Keras Convolutional model.\n",
    "        \"\"\"\n",
    "        _input = Input(shape=(input_data.shape[1],))\n",
    "        texnet_mlp = Dense(16, activation='relu')(_input)\n",
    "        texnet_mlp = Dense(16, activation='relu', kernel_regularizer=l2(0.01))(texnet_mlp)\n",
    "        texnet_mlp = Model(inputs=_input, outputs=texnet_mlp)\n",
    "        return texnet_mlp\n",
    "\n",
    "    def prepare_model(self):\n",
    "        \"\"\" This function initialises the model architecture based on the selected input features.\n",
    "        If only Haralick data is used then only the TexNetMLP model will be initialised. If more than one input feature\n",
    "        is used then the model will be ensembled with a Keras concatenate layer before predictions are done via a final\n",
    "        Dense layer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model: Compiled model either single network (CNN or MLP), or some ensembled model comprised of both model\n",
    "        architectures.\n",
    "        \"\"\"\n",
    "        model_inputs = []\n",
    "        model_outputs = []\n",
    "\n",
    "        # Initialise TexNet Conv2D model if images are given as input.\n",
    "        if self.train_i:\n",
    "            image_model = self.texnet_conv2d(self.train_i_data)\n",
    "            model_inputs.append(image_model.input)\n",
    "            model_outputs.append(image_model.output)\n",
    "\n",
    "        # Initialise TexNet Conv2D model if matrices are given as input.\n",
    "        if self.train_m:\n",
    "            matrix_model = self.texnet_conv2d(self.train_m_data)\n",
    "            model_inputs.append(matrix_model.input)\n",
    "            model_outputs.append(matrix_model.output)\n",
    "\n",
    "        # Initialise TexNet MLP if Haralick features are given as input.\n",
    "        if self.train_h:\n",
    "            haralick_model = self.texnet_mlp(self.test_h_data)\n",
    "            model_inputs.append(haralick_model.input)\n",
    "            model_outputs.append(haralick_model.output)\n",
    "\n",
    "        # If only a singular input feature is used then ensembling is not conducted.\n",
    "        if len(model_outputs) == 1:\n",
    "            final_layer = Dense(1, activation='sigmoid')(model_outputs[0])\n",
    "            model = Model(inputs=model_inputs, outputs=final_layer)\n",
    "        else:\n",
    "            concatenate_model = concatenate(model_outputs)\n",
    "            final_layer = Dense(len(model_outputs), activation='relu')(concatenate_model)\n",
    "            final_layer = Dense(1, activation='sigmoid')(final_layer)\n",
    "            model = Model(inputs=model_inputs, outputs=final_layer)\n",
    "\n",
    "        if len(model_outputs) == 0:\n",
    "            print(\n",
    "                \"Error: No models have been trained!\"\n",
    "                \"Please set a training data set to 'True' so a model can be correctly compiled.\")\n",
    "        else:\n",
    "            return model\n",
    "\n",
    "    def train_model(self, tensor, epochs, batch_size=None, loss_function='mae', optimizer='adam'):\n",
    "        \"\"\" This object will conduct the training step of the compiled model obtained from the 'prepare_model' function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor: Tensorflow Keras model.\n",
    "            Input should be the prepared model obtained from the 'prepare_model' function.\n",
    "        epochs: int\n",
    "            Number of epochs model should run through. Default = 150.\n",
    "        batch_size: int\n",
    "            How many different features should be passed through the model at one time. Default = 1.\n",
    "        loss_function: string\n",
    "            Which loss function the model should be minimising for. Default is Mean Absolute Error (mae).\n",
    "        optimizer: string\n",
    "            Which optimiser the model should be using during training.\n",
    "            Default = 'adam' - Keras Nadam (Adam with Nesterov Momentum) lr = 0.0005.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        train_data: array_like\n",
    "            The split set of training data used during model training\n",
    "        test_data: array_like\n",
    "            The split set of test data\n",
    "        val_data: array_list\n",
    "            The split set of data for validation.\n",
    "        tensor.fit: Tf Keras model\n",
    "            Trained model over the input number of epochs.\n",
    "        \"\"\"\n",
    "        if self.train_i is None and self.train_m is None and self.train_h is None:\n",
    "            print(\"\\n\")\n",
    "            print(\"No data as input! Select a training data set.\")\n",
    "\n",
    "        # Initialise optimizer\n",
    "        if optimizer == 'adam':\n",
    "            optimizer = Nadam(lr=0.0005)\n",
    "        if optimizer == 'sgd':\n",
    "            optimizer = SGD(lr=0.1, decay=1e-6, momentum=0.6)\n",
    "\n",
    "        # Compile the model with the selected optimiser and loss function.\n",
    "        tensor.compile(optimizer=optimizer, loss=loss_function)\n",
    "\n",
    "        train_data = []\n",
    "        test_data = []\n",
    "        val_data = []\n",
    "\n",
    "        if self.train_i:\n",
    "            train_data.append(self.train_i_data)\n",
    "            test_data.append(self.test_i_data)\n",
    "            val_data.append(self.val_i_data)\n",
    "\n",
    "        if self.train_m:\n",
    "            train_data.append(self.train_m_data)\n",
    "            test_data.append(self.test_m_data)\n",
    "            val_data.append(self.val_m_data)\n",
    "\n",
    "        if self.train_h:\n",
    "            train_data.append(self.train_h_data)\n",
    "            test_data.append(self.test_h_data)\n",
    "            val_data.append(self.val_h_data)\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = len(self.train_i_data)\n",
    "\n",
    "        # Return output trained model.\n",
    "        return train_data, test_data, val_data, tensor.fit(train_data, self.train_t, batch_size=batch_size,\n",
    "                                                           epochs=epochs, verbose=1,\n",
    "                                                           validation_data=(val_data, self.val_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the Performance of our Model\n",
    "Now that the model can be prepared we define a set of useful functions for visualising how well our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualisePerformance(object):\n",
    "    \"\"\" This class offers a few of the visualisation functions that display the models performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\" Initialise the object and provide the input data for display.\n",
    "\n",
    "        kwargs: dict\n",
    "            Provide a dictionary of the inputs selected for visualisation.\n",
    "        \"\"\"\n",
    "        self.train_d = kwargs.get('train_data')\n",
    "        self.test_d = kwargs.get('test_data')\n",
    "        self.val_d = kwargs.get('val_data')\n",
    "        self.train_t = kwargs.get('train_target')\n",
    "        self.test_t = kwargs.get('test_target')\n",
    "        self.val_t = kwargs.get('val_target')\n",
    "\n",
    "    def predictions(self, compiled_model, batch_size=None):\n",
    "        \"\"\" This function will compute the predicted values based on the set of\n",
    "        test data passed to the class during initialisation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        compiled model: Tf Keras compiled model.\n",
    "            This should be the model that was trained on output from the 'train_model' function in the 'TexNetModels'\n",
    "            class.\n",
    "        \"\"\"\n",
    "        return compiled_model.predict(self.test_d, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    def display_loss(self, prepared_model):\n",
    "        \"\"\" Displays the various loss values obtained from the predictions made on train, test, and validation data\n",
    "        sets.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        prepared model: Tf Keras model.\n",
    "            This should be the model that was trained on output from the 'prepare_model' function in the 'TexNetModels'\n",
    "            class.\n",
    "        \"\"\"\n",
    "        train_loss = prepared_model.evaluate(self.train_d, self.train_t, verbose=0)\n",
    "        test_loss = prepared_model.evaluate(self.test_d, self.test_t, verbose=0)\n",
    "        val_loss = prepared_model.evaluate(self.val_d, self.val_t, verbose=0)\n",
    "        return ('Train Loss: {}'.format(train_loss),\n",
    "                'Validation Loss: {}'.format(val_loss),\n",
    "                'Test Loss: {}'.format(test_loss))\n",
    "\n",
    "    def compute_accuracy_metrics(self, predicted):\n",
    "        \"\"\" Displays the various errors quantities by comparing actual values with predictions made by the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted: array-like\n",
    "            The predicted values returned from the 'predictions' function.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        MAPE: float64\n",
    "            Mean Absolute Percentage Error\n",
    "        MAE: float64\n",
    "            Mean Absolute Error\n",
    "        MSE: float64\n",
    "            Mean Squared Error\n",
    "        RMSE: float64\n",
    "            Root Mean Squared Error\n",
    "        R2: float64\n",
    "            R2 - Coefficient of determination.\n",
    "        \"\"\"\n",
    "        mape = np.mean(np.abs(self.test_t.values[:, np.newaxis] - predicted / self.test_t.values[:, np.newaxis]))\n",
    "        mae = skm.mean_absolute_error(self.test_t.values, predicted)\n",
    "        mse = skm.mean_squared_error(self.test_t.values, predicted)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = skm.r2_score(self.test_t.values, predicted)\n",
    "        return {'MAPE': mape, 'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "    def plot_loss(self, tensor):\n",
    "        \"\"\" Plots loss over epochs for both training and validation data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor: Tf Keras trained model.\n",
    "            This should be the output trained model from 'train_model' function.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        Plot of loss over epoch.\n",
    "        \"\"\"\n",
    "        plt.plot(tensor.history['loss'])\n",
    "        plt.plot(tensor.history['val_loss'])\n",
    "        plt.title('Model Loss over Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Val'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    def create_prediction_df(self, predicted):\n",
    "        \"\"\" Generate a Pandas DataFrame that contains the associated texture dimension actual values and predicted values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted: array_like\n",
    "            The predicted values returned from the 'predictions' function.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prediction_df: Pandas DataFrame\n",
    "        \"\"\"\n",
    "        prediction_df = pd.DataFrame(self.test_t)\n",
    "        prediction_df['predicated_target'] = predicted\n",
    "        prediction_df = prediction_df.sort_values(by=prediction_df.columns[0], ascending=True)\n",
    "\n",
    "        return prediction_df\n",
    "\n",
    "    def plot_predictions(self, data_frame, dimension):\n",
    "        \"\"\" Generate a plot of predicted values against actual values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        data_frame: Pandas DataFrame\n",
    "            Values obtained from 'create_prediction_df' function\n",
    "        dimension: string\n",
    "            Type of texture dimension plot is being computed for.\n",
    "        \"\"\"\n",
    "        plt.style.use(u'seaborn-whitegrid')\n",
    "\n",
    "        xdata = data_frame.index.format()\n",
    "        ydata = data_frame.iloc[:, 0]\n",
    "        y2data = data_frame.iloc[:, 1]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "        ax.plot(xdata, ydata, 'o--', alpha=0.7, label=\"Subjective {} Values\".format(dimension), c='b')\n",
    "        for x, y in zip(xdata, ydata):\n",
    "            label = \"{:.2f}\".format(y)\n",
    "            plt.annotate(label, (x, y), textcoords=\"offset points\", xytext=(0, 2), ha='center')\n",
    "\n",
    "        ax.plot(xdata, y2data, 'o-', alpha=0.7, label=\"Model Predicted {} Values\".format(dimension), c='g')\n",
    "        for x, y in zip(xdata, y2data):\n",
    "            label = \"{:.2f}\".format(y)\n",
    "            plt.annotate(label, (x, y), textcoords=\"offset points\", xytext=(0, -2), ha='center')\n",
    "\n",
    "        ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        ax.set_title('Subjective {}: Actual Values vs Model Predicted Values'.format(dimension))  # Set title.\n",
    "        ax.set_xlabel('Image Texture', fontsize=18)\n",
    "        ax.set_ylabel('{}'.format(dimension), fontsize=18)\n",
    "        ax.margins(x=0.01)\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "        ax.legend(loc='upper left')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it All Together\n",
    "We have defined the necessary objects that are needed to compile and train our model to make predictions. Now we shall go ahead and intialise everything so that we can make some predictions, and visualise the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise our FeaturesLists object\n",
    "feature_creation = FeaturesLists(IMAGE_DIR, image_size = IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our list of images\n",
    "image_list = feature_creation.create_image_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of matrices, obtain the optimal matrix input values, generate our Haralick features for each image.\n",
    "matrices, inputs, haralick = feature_creation.create_matrix_list(image_list, [1, 2, 4, 6, 8, 10, 15, 20], [0, 45, 90, 135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise our Prepare Data object and pass our list of test textures that we want to retain for evaluating the performance\n",
    "# of our model.\n",
    "prepare_data = PrepareData(TEST_TEXTURE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialise our data into a new data frame that will include additional columns containing our computed feature sets.\n",
    "df = prepare_data.append_feature_data(data_frame = data_frame, image_list = image_list, matrix_list = matrices, haralick_list = haralick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the Log of cluster shade and prominence to better display the range of computed values.\n",
    "for col in [col for col in df.columns if 'har_cls' in col]:\n",
    "    df[\"log_{}\".format(col)] = np.log(np.abs(df[col]))\n",
    "\n",
    "# Values in Haralick data are then rescaled between 0 and 1 if their max is greater than 1.\n",
    "for col in [col for col in df.columns if 'har_' in col and df[col].max() > 1]:\n",
    "    df[col] = prepare_data.scale_data(df[col], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which features we wish to use during training.\n",
    "HARALICK_FEATURES = ['har_homo', 'har_corr', 'har_contrast', 'har_energy', 'har_mean', 'har_stdev', 'log_har_cls_prom', 'log_har_cls_shade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create each of the separate train, test, and validation data sets.\n",
    "train, test, val = prepare_data.split_for_training(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image and matrix data so that it can be passed to our model.\n",
    "train_images = prepare_data.reshape_array(train.image_list, (len(train.image_list), train.image_list[0].shape[0], train.image_list[0].shape[1], 1))\n",
    "test_images = prepare_data.reshape_array(test.image_list, (len(test.image_list), test.image_list[0].shape[0], test.image_list[0].shape[1], 1))\n",
    "val_images = prepare_data.reshape_array(val.image_list, (len(val.image_list), val.image_list[0].shape[0], val.image_list[0].shape[1], 1))\n",
    "\n",
    "train_matrix = prepare_data.reshape_array(train.matrix_list, (len(train.matrix_list), train.matrix_list[0].shape[0], train.matrix_list[0].shape[1], 1))\n",
    "test_matrix = prepare_data.reshape_array(test.matrix_list, (len(test.matrix_list), test.matrix_list[0].shape[0], test.matrix_list[0].shape[1], 1))\n",
    "val_matrix = prepare_data.reshape_array(val.matrix_list, (len(val.matrix_list), val.matrix_list[0].shape[0], val.matrix_list[0].shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise our dictionary that defines which parameters we want to train on.\n",
    "features = {\n",
    "    'image_training':True,\n",
    "    'matrix_training':True,\n",
    "    'haralick_training':True,\n",
    "    'train_image_data':train_images,\n",
    "    'train_matrix_data':train_matrix,\n",
    "    'train_haralick_data':train.loc[:, HARALICK_FEATURES],\n",
    "    'test_image_data':test_images,\n",
    "    'test_matrix_data':test_matrix,\n",
    "    'test_haralick_data':test.loc[:, HARALICK_FEATURES],\n",
    "    'val_image_data':val_images,\n",
    "    'val_matrix_data':val_matrix,\n",
    "    'val_haralick_data':val.loc[:, HARALICK_FEATURES],\n",
    "    'train_target':train[PREDICTOR_VARIABLE] / 100, # Divide predictor variable values by 100\n",
    "    'test_target':test[PREDICTOR_VARIABLE] / 100, \n",
    "    'val_target':val[PREDICTOR_VARIABLE] / 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilise our TexNetModels object and pass to it our feature key word argument dictionary.\n",
    "texNet = TexNetModels(**features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model for training\n",
    "prepared_model = texNet.prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train our model, and produce the split train, test, and validation data sets.\n",
    "train_data, test_data, val_data, tensor_history = texNet.train_model(prepared_model, EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliase key word args for visualising model performance.\n",
    "visualisation_data = {\n",
    "    'train_data':train_data,\n",
    "    'test_data':test_data,\n",
    "    'val_data':val_data,\n",
    "    'train_target':train[PREDICTOR_VARIABLE] / 100, # Divide predictor variable values by 100\n",
    "    'test_target':test[PREDICTOR_VARIABLE] / 100, \n",
    "    'val_target':val[PREDICTOR_VARIABLE] / 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the VisualisePerformance object and pass to it the dictionary of key word params.\n",
    "performance_visualiser = VisualisePerformance(**visualisation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from our trained model.\n",
    "predictions = performance_visualiser.predictions(prepared_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display loss values for each of our data sets.\n",
    "performance_visualiser.display_loss(prepared_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accuracy metrics for predictions by our model.\n",
    "performance_visualiser.compute_accuracy_metrics(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display loss function over no. of epochs.\n",
    "performance_visualiser.plot_loss(tensor_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Data Frame that contains our predictions and real values in ascending order.\n",
    "predictions_df = performance_visualiser.create_prediction_df(predictions)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance of our predictions as a line graph in comparison to our actual values.\n",
    "performance_visualiser.plot_predictions(predictions_df, PREDICTOR_VARIABLE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
