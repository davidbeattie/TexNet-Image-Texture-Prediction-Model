{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultraleap Image Texture Prediction Model Â© Ultraleap Limited 2020\n",
    "\n",
    "Licensed under the Ultraleap closed source licence agreement; you may not use this file except in compliance with the License.\n",
    "\n",
    "A copy of this License is included with this download as a separate document. \n",
    "\n",
    "Alternatively, you may obtain a copy of the license from: https://www.ultraleap.com/closed-source-licence/\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TexNet Data Pre-Processing\n",
    "This Jupyter notebook takes 2 separate data inputs (perceptual data, and image information data), and creates a processed and concatenated data frame that is ready to be passed to the TexNet model as a .csv file. The following Python libraries are required in order to run this notebook.\n",
    "\n",
    "* Pandas (0.25.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas==0.25.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation\n",
    "Firstly, we initialise a few Python library dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepping Functions\n",
    "Next, we define some small utility functions to aid data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_range_scaler(current_value, old_min, old_max, new_min, new_max):\n",
    "    '''Function rescales values to new range.\n",
    "    '''\n",
    "    return ((current_value - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers_iqr(data_frame_col):\n",
    "    '''Function takes data frame column and checks for outliers using IQR.\n",
    "    '''\n",
    "    Q1 = data_frame_col.quantile(0.25)\n",
    "    Q3 = data_frame_col.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return (data_frame_col < (Q1 - 1.5 * IQR)) | (data_frame_col > (Q3 + 1.5 * IQR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime(data_frame):\n",
    "    '''Function to obtain lengths of individual studies, in minutes and seconds.\n",
    "    '''\n",
    "    data_frame[\"End Date\"] = pd.to_datetime(data_frame[\"End Date\"])\n",
    "    data_frame[\"Start Date\"] = pd.to_datetime(data_frame[\"Start Date\"])\n",
    "    data_frame[\"time_seconds\"] = np.abs(data_frame[\"End Date\"] - data_frame[\"Start Date\"])\n",
    "    data_frame[\"time_seconds\"] = data_frame[\"time_seconds\"] / np.timedelta64(1, 's')\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_filter_data(perceptual_data, image_data, dimensions, outlier_filter):\n",
    "    \"\"\"This function concatentates the image data and perceptual data obtained from \n",
    "    our Amazon Mechanical Turk visual roughness perception study into one large data \n",
    "    frame in the correct format.\n",
    "    \n",
    "    Args:\n",
    "        perceptual_data - perceptual data as a Pandas dataframe.\n",
    "        image_data - image data as a Pandas dataframe.\n",
    "        dimensions - list of dimensions that should be appended to the output .csv file.\n",
    "        outlier_filter - boolean to choose whether or not outliers should be filtered based on Median and IQR.\n",
    "\n",
    "    Returns:\n",
    "        data_frame - a concatenated and filtered Pandas dataframe.\n",
    "    \"\"\"\n",
    "    perceptual_data_clean = datetime(perceptual_data)\n",
    "    perceptual_data_clean = perceptual_data[perceptual_data_clean['time_seconds'] < 10800]\n",
    "    image_name_list = image_data['Name']\n",
    "    groups = image_data['Group']\n",
    "\n",
    "    data_frame_collector = {}\n",
    "    for i, dimension in enumerate(dimensions):\n",
    "        new_data_frame = perceptual_data_clean.filter(like=str.title(dimension))\n",
    "        new_data_frame = new_data_frame.T\n",
    "        new_data_frame.index = image_name_list\n",
    "        new_data_frame['group'] = image_data['Group'].values\n",
    "        new_data_frame = new_data_frame[~new_data_frame.index.str.contains('_copy')]\n",
    "        new_data_frame = new_data_frame.sort_index(axis=0)\n",
    "        groups = new_data_frame['group']\n",
    "        new_data_frame = new_data_frame.drop(columns='group')\n",
    "\n",
    "        outlier_list = []\n",
    "\n",
    "        for col in new_data_frame.columns[:]:\n",
    "            value_list = new_data_frame[col].values\n",
    "            new_data_frame[col] = value_range_scaler([value for value in value_list],\n",
    "                                                     new_data_frame[col].values.min(),\n",
    "                                                     new_data_frame[col].values.max(),\n",
    "                                                     0, 100)\n",
    "\n",
    "            outliers = check_outliers_iqr(new_data_frame[col])\n",
    "            outlier_list.append(outliers)\n",
    "\n",
    "        new_data_frame = new_data_frame.T\n",
    "        new_data_frame_unstacked = pd.concat([new_data_frame.unstack().rename(\"{}\".format(dimension))], axis=1)\n",
    "        outlier_list = [item for sublist in outlier_list for item in sublist]\n",
    "\n",
    "        if outlier_filter:\n",
    "            new_data_frame_unstacked = new_data_frame_unstacked[~new_data_frame_unstacked[dimension].isin(\n",
    "                outlier_list)]\n",
    "\n",
    "        new_data_frame_unstacked.index.names = ['tex_name', 'user_no']\n",
    "        new_data_frame_unstacked['tex_name'] = new_data_frame_unstacked.index.get_level_values('tex_name')\n",
    "        new_data_frame_unstacked = new_data_frame_unstacked.reset_index(drop=True)\n",
    "\n",
    "        means = []\n",
    "        medians = []\n",
    "        stds = []\n",
    "\n",
    "        for tex in new_data_frame_unstacked.tex_name.unique():\n",
    "            mean = new_data_frame_unstacked.groupby(\n",
    "                [new_data_frame_unstacked.tex_name == tex])[dimension].mean().tolist()\n",
    "            means.append(mean[1])\n",
    "\n",
    "            median = new_data_frame_unstacked.groupby(\n",
    "                [new_data_frame_unstacked.tex_name == tex])[dimension].median().tolist()\n",
    "            medians.append(median[1])\n",
    "\n",
    "            std = new_data_frame_unstacked.groupby(\n",
    "                [new_data_frame_unstacked.tex_name == tex])[dimension].std().tolist()\n",
    "            stds.append(std[1])\n",
    "\n",
    "        new_data_frame = new_data_frame.T\n",
    "        new_data_frame['mean'] = means\n",
    "        new_data_frame['std'] = stds\n",
    "        new_data_frame['median'] = medians\n",
    "        new_data_frame.columns = ['{}{}'.format(c, '_' + dimension) for c in new_data_frame.columns]\n",
    "        new_data_frame.columns = new_data_frame.columns.str.lower()\n",
    "        new_data_frame.index.name = 'tex_name'\n",
    "\n",
    "        data_frame_collector[i] = pd.DataFrame(new_data_frame)\n",
    "\n",
    "    data_frame_combined = pd.concat(data_frame_collector.values(), sort=False, axis=1)\n",
    "    data_frame = pd.concat([groups, data_frame_combined], axis=1)\n",
    "\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_prepped_model_data(perceptual_data, image_data, dimensions, \n",
    "                              outlier_filter=None, store_data=None):\n",
    "    \"\"\"\n",
    "    This function will output a filtered data frame and store it in the folder, 'input_data', \n",
    "    ready to be used for training the TexNet model. \n",
    "    \n",
    "    Args:\n",
    "        perceptual_data - this is the path to the necessary .csv file containing data from our \n",
    "                          Amazon Mechanical Turkvisual perception user study.\n",
    "        image_data - the path to the .csv file that contains image data information (names etc).\n",
    "        dimensions - list of dimensions that should be aggregated and appended to the output .csv file.\n",
    "        outlier_filter - boolean to determine if data outliers should be filtered via inter-quartile range.\n",
    "        store_data - boolean to state whether data should be stored as an output .csv file.\n",
    "        \n",
    "    Returns:\n",
    "        filtered_data - returns a prepared Pandas data frame that contains the filtered perceptual data \n",
    "                        for each selected texture dimension passed to the function.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get perceptual data .csv file and make a data frame.\n",
    "    if not os.path.exists(perceptual_data):\n",
    "        print(\"The file %s does not exist!\" % perceptual_data)\n",
    "    if isinstance(perceptual_data, pd.DataFrame):\n",
    "        pass\n",
    "    else:\n",
    "        perceptual_data = pd.read_csv(r\"{}\".format(perceptual_data), error_bad_lines=False)\n",
    "\n",
    "    # Get the image info .csv file and make a data frame.\n",
    "    if not os.path.exists(image_data):\n",
    "        print(\"The file %s does not exist!\" % image_data)\n",
    "    if isinstance(image_data, pd.DataFrame):\n",
    "        pass\n",
    "    else:\n",
    "        image_data = pd.read_csv(r\"{}\".format(image_data), error_bad_lines=False)\n",
    "\n",
    "    \"\"\"Check the input dimensions list, if user has passed the value 'all', then filtering will take place on all\n",
    "    texture dimensions.\n",
    "    \"\"\"\n",
    "    if dimensions == 'all':\n",
    "        dimensions = ['roughness', 'stickiness', 'bumpiness', 'hardness', 'warmness']\n",
    "    else:\n",
    "        dimensions = [dimensions]\n",
    "\n",
    "    # A data frame is returned that has been filtered and concatenated.\n",
    "    filtered_data = combine_and_filter_data(perceptual_data, image_data, dimensions, outlier_filter)\n",
    "\n",
    "    # Time information stored for file saving.\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # Input dimensions converted to list\n",
    "    dim_list = \"_\".join([dimension for dimension in dimensions])\n",
    "\n",
    "    \"\"\"Check to see if data should be stored and whether outlier filter has been selected as an additional\n",
    "    filtering step.\n",
    "    \"\"\"\n",
    "    if store_data and outlier_filter:\n",
    "        name = 'input_data/{}_{}_data_outlier_filtered.csv'.format(timestr, dim_list)\n",
    "        name = name.replace('[', '').replace(']', '').replace(\"'\", '').replace(\",\", \"\").replace(\" \", \"\")\n",
    "        filtered_data.to_csv(name, sep=',')  # Store the file.\n",
    "        print(\"File {} has been compiled and stored in  '..input_data/'.\".format(name))\n",
    "    elif store_data:\n",
    "        name = 'input_data/{}_{}_data.csv'.format(timestr, dim_list)\n",
    "        name = name.replace('[', '').replace(']', '').replace(\"'\", '').replace(\",\", \"\").replace(\" \", \"\")\n",
    "        filtered_data.to_csv(name, sep=',')  # Store the file.\n",
    "        print(\"File {} has been compiled and stored in '..input_data/'.\".format(name))\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data and exporting to a .CSV file.\n",
    "Now that we have defined the helper functions that will prepare and concatenate our data sets, we need to provide references to the data itself, then run it all through each function, and finally output the .csv file to a location of our choosing.\n",
    "\n",
    "First, we define the locations of each of our separate data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptual_data = 'input_data/perceptual_data.csv'\n",
    "image_data = 'input_data/image_data.csv'\n",
    "dimensions = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the functions and creating the .csv file.\n",
    "The final step is to simply run the `export_prepped_model_data` script with the correctly supplied input data sets and the output data frame will be created and stored in the, 'input_data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = export_prepped_model_data(perceptual_data, image_data, dimensions, outlier_filter = True, store_data=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
